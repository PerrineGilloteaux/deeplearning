{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "matplotlib.rcParams[\"image.interpolation\"] = None\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, normalize\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "\n",
    "from stardist import random_label_cmap, _draw_polygons, export_imagej_rois\n",
    "from stardist.models import StarDist2D\n",
    "\n",
    "np.random.seed(6)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Based on training from step 2 (model already created), now we create prediction for each independant slice of the 3D confocal images to be processed and save the label. We will create 3D labels from this using the wand tool for example and giving one label to each 3D nucleus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "X = sorted(glob('creating2Dlabelsfor3D/zone'+zone+'/image/*.tif'))\n",
    "X = list(map(imread,X))\n",
    "print(len(X))\n",
    "\n",
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "axis_norm = (0,1)   # normalize channels independently\n",
    "# axis_norm = (0,1,2) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all test images\n",
    "if False:\n",
    "    fig, ax = plt.subplots(7,8, figsize=(16,16))\n",
    "    for i,(a,x) in enumerate(zip(ax.flat, X)):\n",
    "        a.imshow(x if x.ndim==2 else x[...,0], cmap='gray')\n",
    "        a.set_title(i)\n",
    "    [a.axis('off') for a in ax.flat]\n",
    "    plt.tight_layout()\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model\n",
    "\n",
    "If you trained your own StarDist model (and optimized its thresholds) via notebook [2_training.ipynb](2_training.ipynb), then please set `demo_model = False` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.510973, nms_thresh=0.4.\n",
      "Help on StarDist2D in module stardist.models.model2d object:\n",
      "\n",
      "class StarDist2D(stardist.models.base.StarDistBase)\n",
      " |  StarDist2D(config=Config2D(axes='YXC', backbone='unet', grid=(1, 1), n_channel_in=1, n_channel_out=33, n_dim=2, n_rays=32, net_conv_after_unet=128, net_input_shape=(None, None, 1), net_mask_shape=(None, None, 1), train_background_reg=0.0001, train_batch_size=4, train_checkpoint='weights_best.h5', train_checkpoint_epoch='weights_now.h5', train_checkpoint_last='weights_last.h5', train_completion_crop=32, train_dist_loss='mae', train_epochs=400, train_foreground_only=0.9, train_learning_rate=0.0003, train_loss_weights=(1, 0.2), train_n_val_patches=None, train_patch_size=(256, 256), train_reduce_lr={'factor': 0.5, 'patience': 40, 'min_delta': 0}, train_shape_completion=False, train_steps_per_epoch=100, train_tensorboard=True, unet_activation='relu', unet_batch_norm=False, unet_dropout=0.0, unet_kernel_size=(3, 3), unet_last_activation='relu', unet_n_conv_per_depth=2, unet_n_depth=3, unet_n_filter_base=32, unet_pool=(2, 2), unet_prefix='', use_gpu=False), name=None, basedir='.')\n",
      " |  \n",
      " |  StarDist2D model.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  config : :class:`Config` or None\n",
      " |      Will be saved to disk as JSON (``config.json``).\n",
      " |      If set to ``None``, will be loaded from disk (must exist).\n",
      " |  name : str or None\n",
      " |      Model name. Uses a timestamp if set to ``None`` (default).\n",
      " |  basedir : str\n",
      " |      Directory that contains (or will contain) a folder with the given model name.\n",
      " |  \n",
      " |  Raises\n",
      " |  ------\n",
      " |  FileNotFoundError\n",
      " |      If ``config=None`` and config cannot be loaded from disk.\n",
      " |  ValueError\n",
      " |      Illegal arguments, including invalid configuration.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  config : :class:`Config`\n",
      " |      Configuration, as provided during instantiation.\n",
      " |  keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_\n",
      " |      Keras neural network model.\n",
      " |  name : str\n",
      " |      Model name.\n",
      " |  logdir : :class:`pathlib.Path`\n",
      " |      Path to model folder (which stores configuration, weights, etc.)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StarDist2D\n",
      " |      stardist.models.base.StarDistBase\n",
      " |      csbdeep.models.base_model.BaseModel\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, config=Config2D(axes='YXC', backbone='unet', grid=(1, 1), n_channel_in=1, n_channel_out=33, n_dim=2, n_rays=32, net_conv_after_unet=128, net_input_shape=(None, None, 1), net_mask_shape=(None, None, 1), train_background_reg=0.0001, train_batch_size=4, train_checkpoint='weights_best.h5', train_checkpoint_epoch='weights_now.h5', train_checkpoint_last='weights_last.h5', train_completion_crop=32, train_dist_loss='mae', train_epochs=400, train_foreground_only=0.9, train_learning_rate=0.0003, train_loss_weights=(1, 0.2), train_n_val_patches=None, train_patch_size=(256, 256), train_reduce_lr={'factor': 0.5, 'patience': 40, 'min_delta': 0}, train_shape_completion=False, train_steps_per_epoch=100, train_tensorboard=True, unet_activation='relu', unet_batch_norm=False, unet_dropout=0.0, unet_kernel_size=(3, 3), unet_last_activation='relu', unet_n_conv_per_depth=2, unet_n_depth=3, unet_n_filter_base=32, unet_pool=(2, 2), unet_prefix='', use_gpu=False), name=None, basedir='.')\n",
      " |      See class docstring.\n",
      " |  \n",
      " |  train(self, X, Y, validation_data, augmenter=None, seed=None, epochs=None, steps_per_epoch=None)\n",
      " |      Train the neural network with the given data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`\n",
      " |          Input images\n",
      " |      Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`\n",
      " |          Label masks\n",
      " |      validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`)\n",
      " |          Tuple of X,Y validation arrays.\n",
      " |      augmenter : None or callable\n",
      " |          Function with expected signature ``xt, yt = augmenter(x, y)``\n",
      " |          that takes in a single pair of input/label image (x,y) and returns\n",
      " |          the transformed images (xt, yt) for the purpose of data augmentation\n",
      " |          during training. Not applied to validation images.\n",
      " |          Example:\n",
      " |          def simple_augmenter(x,y):\n",
      " |              x = x + 0.05*np.random.normal(0,1,x.shape)\n",
      " |              return x,y\n",
      " |      seed : int\n",
      " |          Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.)\n",
      " |      epochs : int\n",
      " |          Optional argument to use instead of the value from ``config``.\n",
      " |      steps_per_epoch : int\n",
      " |          Optional argument to use instead of the value from ``config``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ``History`` object\n",
      " |          See `Keras training history <https://keras.io/models/model/#fit>`_.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from stardist.models.base.StarDistBase:\n",
      " |  \n",
      " |  export_TF(self, fname=None, single_output=True, upsample_grid=True)\n",
      " |      Export model to TensorFlow's SavedModel format that can be used e.g. in the Fiji plugin\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path of the zip file to store the model\n",
      " |          If None, the default path \"<modeldir>/TF_SavedModel.zip\" is used\n",
      " |      single_output: bool\n",
      " |          If set, concatenates the two model outputs into a single output (note: this is currently mandatory for further use in Fiji)\n",
      " |      upsample_grid: bool\n",
      " |          If set, upsamples the output to the input shape (note: this is currently mandatory for further use in Fiji)\n",
      " |  \n",
      " |  optimize_thresholds(self, X_val, Y_val, nms_threshs=[0.3, 0.4, 0.5], iou_threshs=[0.3, 0.5, 0.7], predict_kwargs=None, optimize_kwargs=None, save_to_json=True)\n",
      " |      Optimize two thresholds (probability, NMS overlap) necessary for predicting object instances.\n",
      " |      \n",
      " |      Note that the default thresholds yield good results in many cases, but optimizing\n",
      " |      the thresholds for a particular dataset can further improve performance.\n",
      " |      \n",
      " |      The optimized thresholds are automatically used for all further predictions\n",
      " |      and also written to the model directory.\n",
      " |      \n",
      " |      See ``utils.optimize_threshold`` for details and possible choices for ``optimize_kwargs``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X_val : list of ndarray\n",
      " |          (Validation) input images (must be normalized) to use for threshold tuning.\n",
      " |      Y_val : list of ndarray\n",
      " |          (Validation) label images to use for threshold tuning.\n",
      " |      nms_threshs : list of float\n",
      " |          List of overlap thresholds to be considered for NMS.\n",
      " |          For each value in this list, optimization is run to find a corresponding prob_thresh value.\n",
      " |      iou_threshs : list of float\n",
      " |          List of intersection over union (IOU) thresholds for which\n",
      " |          the (average) matching performance is considered to tune the thresholds.\n",
      " |      predict_kwargs: dict\n",
      " |          Keyword arguments for ``predict`` function of this class.\n",
      " |          (If not provided, will guess value for `n_tiles` to prevent out of memory errors.)\n",
      " |      optimize_kwargs: dict\n",
      " |          Keyword arguments for ``utils.optimize_threshold`` function.\n",
      " |  \n",
      " |  predict(self, img, axes=None, normalizer=None, n_tiles=None, show_tile_progress=True, **predict_kwargs)\n",
      " |      Predict.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      img : :class:`numpy.ndarray`\n",
      " |          Input image\n",
      " |      axes : str or None\n",
      " |          Axes of the input ``img``.\n",
      " |          ``None`` denotes that axes of img are the same as denoted in the config.\n",
      " |      normalizer : :class:`csbdeep.data.Normalizer` or None\n",
      " |          (Optional) normalization of input image before prediction.\n",
      " |          Note that the default (``None``) assumes ``img`` to be already normalized.\n",
      " |      n_tiles : iterable or None\n",
      " |          Out of memory (OOM) errors can occur if the input image is too large.\n",
      " |          To avoid this problem, the input image is broken up into (overlapping) tiles\n",
      " |          that are processed independently and re-assembled.\n",
      " |          This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).\n",
      " |          ``None`` denotes that no tiling should be used.\n",
      " |      show_tile_progress: bool\n",
      " |          Whether to show progress during tiled prediction.\n",
      " |      predict_kwargs: dict\n",
      " |          Keyword arguments for ``predict`` function of Keras model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (:class:`numpy.ndarray`,:class:`numpy.ndarray`)\n",
      " |          Returns the tuple (`prob`, `dist`) of per-pixel object probabilities and star-convex polygon/polyhedra distances.\n",
      " |  \n",
      " |  predict_instances(self, img, axes=None, normalizer=None, prob_thresh=None, nms_thresh=None, n_tiles=None, show_tile_progress=True, verbose=False, predict_kwargs=None, nms_kwargs=None, overlap_label=None)\n",
      " |      Predict instance segmentation from input image.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      img : :class:`numpy.ndarray`\n",
      " |          Input image\n",
      " |      axes : str or None\n",
      " |          Axes of the input ``img``.\n",
      " |          ``None`` denotes that axes of img are the same as denoted in the config.\n",
      " |      normalizer : :class:`csbdeep.data.Normalizer` or None\n",
      " |          (Optional) normalization of input image before prediction.\n",
      " |          Note that the default (``None``) assumes ``img`` to be already normalized.\n",
      " |      prob_thresh : float or None\n",
      " |          Consider only object candidates from pixels with predicted object probability\n",
      " |          above this threshold (also see `optimize_thresholds`).\n",
      " |      nms_thresh : float or None\n",
      " |          Perform non-maximum suppression that considers two objects to be the same\n",
      " |          when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).\n",
      " |      n_tiles : iterable or None\n",
      " |          Out of memory (OOM) errors can occur if the input image is too large.\n",
      " |          To avoid this problem, the input image is broken up into (overlapping) tiles\n",
      " |          that are processed independently and re-assembled.\n",
      " |          This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).\n",
      " |          ``None`` denotes that no tiling should be used.\n",
      " |      show_tile_progress: bool\n",
      " |          Whether to show progress during tiled prediction.\n",
      " |      predict_kwargs: dict\n",
      " |          Keyword arguments for ``predict`` function of Keras model.\n",
      " |      nms_kwargs: dict\n",
      " |          Keyword arguments for non-maximum suppression.\n",
      " |      overlap_label: scalar or None\n",
      " |          if not None, label the regions where polygons overlap with that value\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (:class:`numpy.ndarray`, dict)\n",
      " |          Returns a tuple of the label instances image and also\n",
      " |          a dictionary with the details (coordinates, etc.) of all remaining polygons/polyhedra.\n",
      " |  \n",
      " |  predict_instances_big(self, img, axes, block_size, min_overlap, context=None, labels_out=None, labels_out_dtype=<class 'numpy.int32'>, show_progress=True, **kwargs)\n",
      " |      Predict instance segmentation from very large input images.\n",
      " |      \n",
      " |      Intended to be used when `predict_instances` cannot be used due to memory limitations.\n",
      " |      This function will break the input image into blocks and process them individually\n",
      " |      via `predict_instances` and assemble all the partial results. If used as intended, the result\n",
      " |      should be the same as if `predict_instances` was used directly on the whole image.\n",
      " |      \n",
      " |      **Important**: The crucial assumption is that all predicted object instances are smaller than\n",
      " |                     the provided `min_overlap`. Also, it must hold that: min_overlap + 2*context < block_size.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      >>> img.shape\n",
      " |      (20000, 20000)\n",
      " |      >>> labels, polys = model.predict_instances_big(img, axes='YX', block_size=4096,\n",
      " |                                                      min_overlap=128, context=128, n_tiles=(4,4))\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      img: :class:`numpy.ndarray` or similar\n",
      " |          Input image\n",
      " |      axes: str\n",
      " |          Axes of the input ``img`` (such as 'YX', 'ZYX', 'YXC', etc.)\n",
      " |      block_size: int or iterable of int\n",
      " |          Process input image in blocks of the provided shape.\n",
      " |          (If a scalar value is given, it is used for all spatial image dimensions.)\n",
      " |      min_overlap: int or iterable of int\n",
      " |          Amount of guaranteed overlap between blocks.\n",
      " |          (If a scalar value is given, it is used for all spatial image dimensions.)\n",
      " |      context: int or iterable of int, or None\n",
      " |          Amount of image context on all sides of a block, which is discarded.\n",
      " |          If None, uses an automatic estimate that should work in many cases.\n",
      " |          (If a scalar value is given, it is used for all spatial image dimensions.)\n",
      " |      labels_out: :class:`numpy.ndarray` or similar, or None, or False\n",
      " |          numpy array or similar (must be of correct shape) to which the label image is written.\n",
      " |          If None, will allocate a numpy array of the correct shape and data type ``labels_out_dtype``.\n",
      " |          If False, will not write the label image (useful if only the dictionary is needed).\n",
      " |      labels_out_dtype: str or dtype\n",
      " |          Data type of returned label image if ``labels_out=None`` (has no effect otherwise).\n",
      " |      show_progress: bool\n",
      " |          Show progress bar for block processing.\n",
      " |      kwargs: dict\n",
      " |          Keyword arguments for ``predict_instances``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (:class:`numpy.ndarray` or False, dict)\n",
      " |          Returns the label image and a dictionary with the details (coordinates, etc.) of the polygons/polyhedra.\n",
      " |  \n",
      " |  prepare_for_training(self, optimizer=None)\n",
      " |      Prepare for neural network training.\n",
      " |      \n",
      " |      Compiles the model and creates\n",
      " |      `Keras Callbacks <https://keras.io/callbacks/>`_ to be used for training.\n",
      " |      \n",
      " |      Note that this method will be implicitly called once by :func:`train`\n",
      " |      (with default arguments) if not done so explicitly beforehand.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      optimizer : obj or None\n",
      " |          Instance of a `Keras Optimizer <https://keras.io/optimizers/>`_ to be used for training.\n",
      " |          If ``None`` (default), uses ``Adam`` with the learning rate specified in ``config``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from stardist.models.base.StarDistBase:\n",
      " |  \n",
      " |  thresholds\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from csbdeep.models.base_model.BaseModel:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  load_weights(self, name='weights_best.h5')\n",
      " |      Load neural network weights from model folder.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |          Name of HDF5 weight file (as saved during or after training).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from csbdeep.models.base_model.BaseModel:\n",
      " |  \n",
      " |  from_pretrained(name_or_alias=None) from abc.ABCMeta\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from csbdeep.models.base_model.BaseModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    model = StarDist2D(None, name='stardistGutnewdatarays64', basedir='models')\n",
    "    help(model)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Make sure to normalize the input image beforehand or supply a `normalizer` to the prediction function.\n",
    "\n",
    "Calling `model.predict_instances` will\n",
    "- predict object probabilities and star-convex polygon distances (see `model.predict` if you want those)\n",
    "- perform non-maximum suppression (with overlap threshold `nms_thresh`) for polygons above object probability threshold `prob_thresh`.\n",
    "- render all remaining polygon instances in a label image\n",
    "- return the label instances image and also the details (coordinates, etc.) of all remaining polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paul-gilloteaux-p\\anaconda3\\lib\\site-packages\\csbdeep\\io\\__init__.py:40: UserWarning: Converting data type from 'int32' to ImageJ-compatible 'int16'.\n",
      "  warnings.warn(\"Converting data type from '%s' to ImageJ-compatible '%s'.\" % (t, np.dtype(t_new)))\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(X)):\n",
    "    img = normalize(X[i], 1,99.8, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img)\n",
    "    #plt.figure(figsize=(8,8)) \n",
    "    #plt.imshow(img if img.ndim==2 else img[...,0], clim=(0,1), cmap='gray')\n",
    "    #plt.imshow(labels, cmap=lbl_cmap, alpha=0.5)\n",
    "    #plt.axis('off');\n",
    "    save_tiff_imagej_compatible('creating2Dlabelsfor3D\\zone'+zone+'\\label\\example_image'+str(i)+'.tif', img, axes='YX')\n",
    "    save_tiff_imagej_compatible('creating2Dlabelsfor3D\\zone'+zone+'\\label\\example_labels'+str(i)+'.tif', labels, axes='YX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
